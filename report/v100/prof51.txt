==5465== NVPROF is profiling process 5465, command: ./a.out 5 1
==5465== Profiling application: ./a.out 5 1
==5465== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   43.71%  50.5155s    210000  240.55us  218.94us  376.09us  reduce(point**, point**, int*, int)
                   26.84%  31.0190s    210001  147.71us  145.34us  167.42us  sieve(int, int, int*, int**, int**, point*, point)
                    3.96%  4.57810s    210001  21.800us  20.000us  3.9214ms  d_boxpart(int**, int*, int, point*, point)
                    3.59%  4.15302s    210000  19.776us  14.495us  25.120us  d_update_pos_mpcd(point*, point*, double, point, int)
                    3.23%  3.73734s     21000  177.97us  4.8000us  2.8271ms  d_nbrc(point*, point*, point*, point*, point, int*, int**, int**, int*, int, double, double)
                    2.57%  2.97432s    210000  14.163us  12.160us  378.30us  d_dump(point*, point*, double*, int)
                    2.18%  2.52151s    210000  12.007us  3.5840us  179.71us  d_fluid_colloid_collision(int*, point*, point*, point*, point*, point*, double, double, double, double, point*, point, double, int, double, int**, point**, point**, curandStateXORWOW*)
                    1.59%  1.83912s    463002  3.9720us  1.0870us  236.74us  imemset(int*, int)
                    1.33%  1.53342s     21000  73.019us  69.920us  79.008us  d_velfl(point*, point*, int**, int*, point**, point)
                    1.04%  1.20466s    210000  5.7360us  4.9270us  24.576us  d_update_activity_direction(point*, point*, double, int)
                    0.97%  1.11882s    210001  5.3270us  4.0000us  157.06us  d_neighbour_list_mpcd(int**, int*, int**, int**, int*, int**, point*, point*, int, int, int, point)
                    0.93%  1.07476s    210000  5.1170us  4.0630us  23.744us  d_update_pos_md(point*, point*, point*, point*, double, double, point, int)
                    0.91%  1.05254s    210000  5.0120us  3.2310us  24.896us  update_fcc(point**, point**, point*, point*, int*, int, double, double, double)
                    0.88%  1.01548s     21000  48.356us  46.016us  55.168us  d_rotate(int*, int**, point*, point*, point, double, double)
                    0.85%  980.28ms     21000  46.680us  29.472us  103.14us  d_velc(point*, point*, int**, int*, int, double, double, double)
                    0.83%  955.95ms    210000  4.5520us  3.1030us  17.472us  d_update_vel_colloid(point*, point*, point*, double, double, int)
                    0.74%  855.47ms    210001  4.0730us  1.6950us  24.095us  d_compute_force_md(point*, int*, int**, point*, double, double, double, double, double, double, double, double*, point, int)
                    0.71%  823.79ms    210001  3.9220us  1.3120us  24.480us  d_neighbour_list_md(int**, int*, point*, int, double, point)
                    0.66%  766.89ms     21000  36.518us  34.239us  254.56us  d_cellvel(point*, point*, int**, int*, point)
                    0.61%  707.44ms     21000  33.687us  31.040us  40.000us  d_rotate_mat(point*, point*, point*, point**, int*, int**, int, point, double, double, curandStateXORWOW*)
                    0.50%  581.77ms     21000  27.703us  24.736us  608.35us  d_cellpart(int**, int*, int, point*, point, point)
                    0.34%  389.99ms    105001  3.7140us  1.6640us  9.5680us  [CUDA memcpy DtoH]
                    0.21%  243.21ms     21001  11.580us  8.8640us  14.400us  void thrust::cuda_cub::cub::DeviceReduceKernel<thrust::cuda_cub::cub::DeviceReducePolicy<point, int, add_point>::Policy600, point*, point*, int, add_point>(int, add_point, thrust::cuda_cub::cub::DeviceReducePolicy<point, int, add_point>::Policy600, thrust::cuda_cub::cub::GridEvenShare<add_point>, point*)
                    0.16%  190.53ms     42001  4.5360us  3.0400us  11.552us  void thrust::cuda_cub::cub::DeviceReduceSingleTileKernel<thrust::cuda_cub::cub::DeviceReducePolicy<point, int, add_point>::Policy600, point*, thrust::detail::normal_iterator<thrust::pointer<point, thrust::cuda_cub::par_t, thrust::use_default, thrust::use_default>>, int, add_point, point>(int, add_point, thrust::cuda_cub::cub::DeviceReducePolicy<point, int, add_point>::Policy600, point*, point)
                    0.15%  172.05ms     21000  8.1920us  5.6640us  10.528us  void thrust::cuda_cub::cub::DeviceReduceKernel<thrust::cuda_cub::cub::DeviceReducePolicy<double, int, add_double>::Policy600, thrust::cuda_cub::transform_input_iterator_t<double, point*, mod_value>, double*, int, add_double>(int, add_double, thrust::cuda_cub::cub::DeviceReducePolicy<double, int, add_double>::Policy600, thrust::cuda_cub::cub::GridEvenShare<add_double>, double)
                    0.13%  147.36ms     42000  3.5080us  1.8230us  8.0320us  void thrust::cuda_cub::cub::DeviceReduceSingleTileKernel<thrust::cuda_cub::cub::DeviceReducePolicy<double, int, add_double>::Policy600, thrust::cuda_cub::transform_input_iterator_t<double, point*, mod_value>, thrust::detail::normal_iterator<thrust::pointer<double, thrust::cuda_cub::par_t, thrust::use_default, thrust::use_default>>, int, add_double, double>(int, add_double, thrust::cuda_cub::cub::DeviceReducePolicy<double, int, add_double>::Policy600, double, point*)
                    0.11%  121.52ms     42001  2.8930us     896ns  8.8960us  void thrust::cuda_cub::core::_kernel_agent<thrust::cuda_cub::__parallel_for::ParallelForAgent<thrust::cuda_cub::for_each_f<thrust::pointer<point, thrust::cuda_cub::par_t, thrust::use_default, thrust::use_default>, thrust::detail::wrapped_function<thrust::detail::allocator_traits_detail::gozer, void>>, long>, thrust::cuda_cub::for_each_f<thrust::pointer<point, thrust::cuda_cub::par_t, thrust::use_default, thrust::use_default>, thrust::detail::wrapped_function<thrust::detail::allocator_traits_detail::gozer, void>>, long>(thrust::cuda_cub::par_t, thrust::use_default)
                    0.06%  74.386ms     21000  3.5420us  2.8800us  8.0320us  void thrust::cuda_cub::cub::DeviceReduceSingleTileKernel<thrust::cuda_cub::cub::DeviceReducePolicy<double, int, add_double>::Policy600, double*, thrust::detail::normal_iterator<thrust::pointer<double, thrust::cuda_cub::par_t, thrust::use_default, thrust::use_default>>, int, add_double, double>(int, add_double, thrust::cuda_cub::cub::DeviceReducePolicy<double, int, add_double>::Policy600, double*, double)
                    0.06%  68.696ms     21000  3.2710us  2.2390us  13.184us  set_rr(point*, curandStateXORWOW*)
                    0.05%  62.909ms     11000  5.7180us  4.8310us  14.400us  calc_upd(int, int*, int*, point**, point**, point*)
                    0.05%  54.944ms     11000  4.9940us  3.7750us  15.648us  helper_upd(int, int*, int*, int*, point**, point**, int**, point*, point*, point*, point*, point, double)
                    0.01%  14.136ms         1  14.136ms  14.136ms  14.136ms  d_create_box(int**, point)
                    0.01%  9.9027ms         1  9.9027ms  9.9027ms  9.9027ms  curand_setup(curandStateXORWOW*, int)
                    0.00%  1.0904ms         1  1.0904ms  1.0904ms  1.0904ms  d_initialize_fluid(point*, point*, point*, int, int, double, double, double, point, curandStateXORWOW*)
                    0.00%  418.65us         1  418.65us  418.65us  418.65us  initialize_colloid(point*, point*, point*, int, double, double, double, double, double, point, curandStateXORWOW*)
                    0.00%  14.304us         1  14.304us  14.304us  14.304us  conserv_mom(point*, point, int)
                    0.00%  8.4160us         1  8.4160us  8.4160us  8.4160us  d_tumble(point*, point*, point, int, curandStateXORWOW*)
      API calls:   34.05%  62.0119s    147002  421.84us  6.2590us  18.422ms  cudaDeviceSynchronize
                   25.52%  46.4673s   3572016  13.008us  5.2770us  84.213ms  cudaLaunch
                   17.65%  32.1462s    210002  153.08us  9.7050us  7.5410ms  cudaMalloc
                   11.91%  21.6813s    210002  103.24us  9.3920us  4.9215ms  cudaFree
                    4.48%  8.16233s  24781093     329ns     126ns  21.773ms  cudaSetupArgument
                    2.19%  3.98830s    105001  37.983us  19.451us  84.583ms  cudaMemcpyAsync
                    1.78%  3.24244s     95750  33.863us  6.2760us  1.98523s  cudaMallocManaged
                    0.94%  1.71162s    252003  6.7920us  2.6420us  4.0552ms  cudaFuncGetAttributes
                    0.80%  1.46536s   3572016     410ns     140ns  927.54us  cudaConfigureCall
                    0.36%  662.72ms    105001  6.3110us  2.9460us  3.6249ms  cudaStreamSynchronize
                    0.08%  152.35ms     84002  1.8130us     737ns  767.71us  cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
                    0.07%  134.45ms    126003  1.0670us     431ns  766.74us  cudaDeviceGetAttribute
                    0.07%  131.04ms    126003  1.0390us     393ns  86.297us  cudaGetDevice
                    0.06%  108.04ms    231004     467ns     126ns  1.4599ms  cudaPeekAtLastError
                    0.03%  47.871ms    105001     455ns     183ns  761.55us  cudaGetLastError
                    0.00%  402.58us        94  4.2820us     177ns  248.86us  cuDeviceGetAttribute
                    0.00%  263.80us         1  263.80us  263.80us  263.80us  cuDeviceTotalMem
                    0.00%  19.029us         1  19.029us  19.029us  19.029us  cuDeviceGetName
                    0.00%  2.2130us         3     737ns     205ns  1.5340us  cuDeviceGetCount
                    0.00%  1.1960us         2     598ns     270ns     926ns  cuDeviceGet

==5465== Unified Memory profiling result:
Device "Tesla V100-SXM2-16GB (0)"
   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name
   21249  4.2441KB  4.0000KB  256.00KB  88.08203MB  155.6240ms  Host To Device
   21083  4.2197KB  4.0000KB  60.000KB  86.89453MB  83.26295ms  Device To Host
   21126         -         -         -           -   3.693412s  Gpu page fault groups
      80  4.0000KB  4.0000KB  4.0000KB  320.0000KB           -  Memory thrashes
Total CPU Page faults: 21010
Total CPU thrashes: 80
==5465== Warning: Some profiling data are not recorded. Make sure cudaProfilerStop() or cuProfilerStop() is called before application exit to flush profile data.
